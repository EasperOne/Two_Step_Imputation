// nextflow.config

// Define pipeline parameters with default values
params {
    // Input/Output Options
    outdir = './results' // Default output directory
    cohorts_csv = 'Cohorts_Info.csv' // Path to the cohort information CSV

    // Reference Files
    fasta = '/path/to/human_g1k_v37.fasta' // !!! PLEASE UPDATE THIS PATH !!!
    gmap = '/path/to/genetic_map_hg19_withX.txt.gz' // !!! PLEASE UPDATE THIS PATH !!!

    // Tool Paths (Specify paths or ensure they are in the system PATH)
    // Alternatively, we can use containers (e.g., Conda or Docker) later
    bcftools = 'bcftools'
    tabix = 'tabix'
    minimac4 = 'minimac4'
    eagle = '/path/to/Eagle_v2.4.1/eagle' // !!! PLEASE UPDATE THIS PATH (if not in PATH) !!!
    vcftools = 'vcftools'
    perl = 'perl'
    rscript = 'Rscript' // Assuming Rscript is in PATH

    // Script Paths (Relative to the pipeline launch directory or absolute)
    // Assumes scripts are in the same directory as nextflow.config/main.nf
    // Consider moving scripts to a 'bin/' directory for better organization
    align_script = "${baseDir}/Alignment.sh"
    vcf_bcf_script = "${baseDir}/VCF_BCF.sh"
    phase_script = "${baseDir}/phase.sh"
    convert_refp_script = "${baseDir}/convert_RefP.sh"
    minimac4_script = "${baseDir}/minimac4.sh"
    r_input_script = "${baseDir}/R_Input.sh"
    r_command_script = "${baseDir}/R_Command.sh"
    vcf_filter_script = "${baseDir}/VCF_Filter_Vcftools.sh"
    merge_vcf_script = "${baseDir}/Merge_VCF_BCFtools.sh"
    extract_info_pl = "${baseDir}/extract_info_VCF.pl" // Perl script used by R_Input.sh
    snp_select_r = "${baseDir}/SNP_Selection.R" // R script used by R_Command.sh

    // Pipeline Specific Parameters (from original config.sh)
    cpus = 12 // Default CPUs for tasks
    rounds = 5 // Minimac4 rounds parameter

    // Reference Panel for Imputation (REQUIRED)
    // Example: '/path/to/reference_panel/chr{1..22,X}.m3vcf.gz'
    ref_panel_m3vcf = null // !!! PLEASE PROVIDE PATH/GLOB PATTERN !!!

    // Add other necessary parameters from original scripts if needed
}

// Define Process specific configurations
process {
    // Example: Define default cpus and memory
    cpus = { params.cpus }
    memory = '10.GB' // Adjust as needed based on tool requirements

    // Error strategy (e.g., retry, ignore, finish, terminate)
    errorStrategy = 'finish' // Stop processing failed job's downstream tasks, but allow others to continue

    // Default directory for process outputs (can be overridden per process)
    // publishDir = params.outdir // Or specify per process
}

// Define Executor (default is 'local')
executor {
    name = 'local'
    cpus = params.cpus // Max CPUs for local execution
    // queueSize = 4 // Limit number of parallel jobs if needed
}

// Conda or Docker configuration (Recommended for dependency management)
// conda.enabled = true // Uncomment if using conda
// docker.enabled = true // Uncomment if using docker
// docker.runOptions = '-u $(id -u):$(id -g)' // Ensure proper file permissions with Docker

// Profiles (Example for standard execution vs test)
// profiles {
//     standard { includeConfig 'conf/standard.config' }
//     test { includeConfig 'conf/test.config' }
// }

// Enable pipeline reporting options
timeline {
    enabled = true
    file = "${params.outdir}/pipeline_info/timeline.html"
}
report {
    enabled = true
    file = "${params.outdir}/pipeline_info/report.html"
}
trace {
    enabled = true
    file = "${params.outdir}/pipeline_info/trace.txt"
    fields = 'task_id,name,status,exit,duration,realtime,%cpu,%mem,rss,vmem,rchar,wchar,syscr,syscw,read_bytes,write_bytes' // Detailed trace fields
}

// Manifest information (optional)
manifest {
    name = 'Two-Step-Imputation-nf'
    description = 'Nextflow implementation of the Two-Step Imputation pipeline'
    author = 'Your Name' // Add your name/organization
    mainScript = 'main.nf'
    nextflowVersion = '>=21.10.3' // Specify minimum required Nextflow version
    version = '1.0.0'
} 